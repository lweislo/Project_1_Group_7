{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,   2000,   4000,   6000,   8000,  10000,  12000,  14000,\n",
       "        16000,  18000,  20000,  22000,  24000,  26000,  28000,  30000,\n",
       "        32000,  34000,  36000,  38000,  40000,  42000,  44000,  46000,\n",
       "        48000,  50000,  52000,  54000,  56000,  58000,  60000,  62000,\n",
       "        64000,  66000,  68000,  70000,  72000,  74000,  76000,  78000,\n",
       "        80000,  82000,  84000,  86000,  88000,  90000,  92000,  94000,\n",
       "        96000,  98000, 100000, 102000, 104000, 106000, 108000, 110000,\n",
       "       112000, 114000, 116000, 118000, 120000, 122000, 124000, 126000,\n",
       "       128000, 130000, 132000, 134000, 136000, 138000, 140000, 142000,\n",
       "       144000, 146000, 148000, 150000, 152000, 154000, 156000, 158000,\n",
       "       160000, 162000, 164000, 166000, 168000, 170000, 172000, 174000,\n",
       "       176000])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "# ------- STUFF WE MIGHT NEED LATER ----------\n",
    "# import matplotlib.pyplot as plt\n",
    "# import gmaps\n",
    "import urllib\n",
    "import time\n",
    "# import seaborn as sbn\n",
    "# from scipy import stats\n",
    "\n",
    "\n",
    "# # Gmaps API Keys\n",
    "# from config import (gkey)\n",
    "\n",
    "# # Configure gmaps\n",
    "# gmaps.configure(api_key=gkey)\n",
    "\n",
    "# Creating an array of ranges to iterate through all the API calls\n",
    "arr = np.arange(0, 178000, 2000)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This API request somehow limits the number of records returned to 2000. But we can download all of them from the site\n",
    "# as a json file. However, if we want we can iterate through the 178000 records 89 times and get them all :)\n",
    "\n",
    "base_url = \"https://services.arcgis.com/v400IkDOw1ad7Yad/arcgis/rest/services/Fire_Incidents_Public/FeatureServer/0/query?\"\n",
    "\n",
    "field_list = \"OBJECTID,incident_number,incident_type,incident_type_description,arrive_date_time,dispatch_date_time,exposure,platoon,station,address,address2,apt_room,GlobalID,cleared_date_time\"\n",
    "parameters = f\"where=1%3D1&outFields={field_list}&outSR=4326&f=json\"\n",
    "\n",
    "set_length = 1\n",
    "\n",
    "# resultsOffset is the record to start with, resultRecordCount is the number of records to return, max=2000\n",
    "#For iterating through API calls to get all the data. We know there are 177,738 Rows, so we need to run this 89 times.\n",
    "\n",
    "records = f'&resultOffset={set_length}&resultRecordCount=2000'\n",
    "\n",
    "# fire_data = requests.get(base_url + parameters + records).json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like we can iterate through the calls to get all the records.\n",
    "# Here is a function that iterates through a list and returns all the JSON data to a hard file\n",
    "\n",
    "def arcgis_api(sets):\n",
    "    fire_data = []\n",
    "    # Work with the log file to record the API calls/errors\n",
    "    timestr = time.strftime('%Y%m%d-%H%M%S')\n",
    "    log = 'log_' + timestr + '.txt'\n",
    "    print(f'Logging API calls in {log}')\n",
    "\n",
    "    with open(log, 'a+') as f:\n",
    "\n",
    "        for n in sets:\n",
    "            status = (f'Getting data for records {n}: {n+2000}... ')\n",
    "            print(status)\n",
    "            #Perform the API call on ARCGIS\n",
    "            try:\n",
    "                url = base_url + parameters + f'&resultOffset={n}&resultRecordCount=2000'\n",
    "                records = requests.get(url).json()\n",
    "                f.write(url)\n",
    "                fire_data.append(records)\n",
    "            #Log the result\n",
    "                msg = 'Success!\\n'\n",
    "                f.write(msg)\n",
    "                print(msg)\n",
    "                time.sleep(30)\n",
    "            except DecodingError:\n",
    "                msg = f'There was an error with the set starting with record {n}\\n'\n",
    "                f.write(msg)\n",
    "                print(msg)\n",
    "            except ContentDecodingError:\n",
    "                msg = f'There was an error with the set starting with record {n}\\n'\n",
    "                f.write(msg)\n",
    "                print(msg)\n",
    "    with open('fire' + timestr + '.txt', 'a+') as file:\n",
    "        print(f'Dumping json data to {file}')\n",
    "        json.dump(fire_data, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging API calls in log_20190111-122851.txt\n",
      "Getting data for records 0: 2000... \n",
      "Success!\n",
      "\n",
      "Getting data for records 2000: 4000... \n",
      "Success!\n",
      "\n",
      "Getting data for records 4000: 6000... \n",
      "Success!\n",
      "\n",
      "Getting data for records 6000: 8000... \n",
      "Success!\n",
      "\n",
      "Getting data for records 8000: 10000... \n",
      "Success!\n",
      "\n",
      "Getting data for records 10000: 12000... \n",
      "Success!\n",
      "\n",
      "Getting data for records 12000: 14000... \n",
      "Success!\n",
      "\n",
      "Getting data for records 14000: 16000... \n",
      "Success!\n",
      "\n",
      "Getting data for records 16000: 18000... \n",
      "Success!\n",
      "\n",
      "Getting data for records 18000: 20000... \n",
      "Success!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calling the function with the array created above\n",
    "# that will do the 89 API calls and save all the data to the fire_timestamp_txt file\n",
    "# There will also be a logfile of the transactions\n",
    "arcgis_api(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "firefile = 'fire20190111-120039.txt'\n",
    "with open(firefile) as jsonfile:\n",
    "    fire_data = json.load(jsonfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OBJECTID': 474765,\n",
       " 'incident_number': '07-0031665',\n",
       " 'incident_type': None,\n",
       " 'incident_type_description': 'NULL',\n",
       " 'arrive_date_time': 1195125420000,\n",
       " 'dispatch_date_time': 1195125000000,\n",
       " 'exposure': 0,\n",
       " 'platoon': ' ',\n",
       " 'station': None,\n",
       " 'address': '6647 LAKE HILL DR RALEIGH, NC 27601',\n",
       " 'address2': '',\n",
       " 'apt_room': '0',\n",
       " 'GlobalID': '5c2e9c89-78d7-4348-bd95-23a69f4039aa',\n",
       " 'cleared_date_time': 1195125900000}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Once we have all the json information we can parse them out as such\n",
    "\n",
    "# I'm stuck here: The call data for each\n",
    "fire_data[0]['features'][0]['attributes']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': -78.62660452385826, 'y': 35.870212857675455}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_data[0]['features'][0]['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lon = []\n",
    "lat = []\n",
    "for item in incident_list:\n",
    "    incidents.append(item['attributes'])\n",
    "    lon.append(item['geometry']['x'])\n",
    "    lat.append(item['geometry']['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(incidents)\n",
    "df['Lat'] = lat\n",
    "df['Lon'] = lon\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
